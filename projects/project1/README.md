# Machine Learning - Class Project 1

This is the directory for the first class project of the Machine Learning course of Fall 2017 at EPFL. This file contains practical information on the project implementation and how to run it. For more detailed explanation of the project (models implemented, hyperparameter choosing, result validation...), please refer to the report (`report.pdf`). 

## Project structure

The project has the following folder (and file) structure:

* `data/`. Directory containing input data, namely `test.csv` and `train.csv` given by Kaggle.
* `docs/`. Directory containing the report both as `report.pdf` and `report.txt` and the plots included in this report.  
* `out/`. Directory containing the output generated by the program, which contains files following `submission-{timestamp}.csv`. This output is compliant with the required format by Kaggle (described in `data/sample-submission.csv`).
* `scripts/`. Actual Python code of the implementation.
    * `check.py`. Runnable file to check that Least Squares, Linear Gradient Descent and Linear Stochastic Gradient Descent converge to the same value. 
    * `clean_data.py`. Functions implementing pre-processing of input data.
    * `helpers.py`. Helper methods for ML algorithms.
    * `implementations.py`. Main implementations of the ML algorithms required in the project statement.
    * `parsers.py`. Functions for loading and storing data.
    * `plots.py`. Methods for generating plots (both supporting and for the report).
    * `run.py`. Entry point of the program containing the `main` routine.
    * `test.py`. Runnable file that implements 4-fold cross validation.
    * `validation.py`. Functions for testing and validating results of different models, data cleaning and hyperparameters.
* `tmp/`. Folder containing cached data files.
* `clear.sh`. Clear all execution-derived data files (`out/` and `tmp/`) folders.

## Environment

The required environment for running the code and reproducing the results is a computer with a valid installation of Python 3. More specifically, [Python 3.6](https://docs.python.org/3.6/) is used.

Besides that (and the built-in Python libraries), the following packages are used and have to be installed:

* [NumPy 1.13.3](http://www.numpy.org). `pip3 install --user numpy==1.13.3`
* [Matplotlib 2.0.2](https://matplotlib.org). `pip3 install --user matplotlib==2.0.2`

## Running

### Main program

To run the main program, the `run.py` has to be executed from the scripts folder:

```
cd scripts/
python3 run.py
```

There are no command line arguments. It will look for a `train.csv` file located on `../data/` for training data and the same for `test.csv` and testing. Outputs will be generated in the `../out/` folder.

The program will output the following progress updates through the standard output:

```
PARSING TRAIN
PARSING TEST
FILTERING DATA
BUILDING POLYNOMIALS
LEARNING MODEL BY LEAST SQUARES
PREDICTING VALUES
EXPORTING CSV
```

### Test

To run different validations, the `test.py` has to be executed from the scrips folder:

```
cd scripts/
python3 run.py
```
There are three command line arguments: 

```
usage: test.py [-h] [--filter FILTER] [--method METHOD] [--X X]

optional arguments:
  -h, --help       show this help message and exit
  --filter FILTER  choose the pre-processing data way 0: raw data 1:
                   standardize 2: standardize + discard outliers 3: remove
                   features with -999 values 4: remove data points with -999
                   values
  --method METHOD  choose between Least Squares ('LS') or Regularized Logistic
                   Regression ('RLR')
  --X X            choose between X-validation among different degrees ('BD')
                   or lambdas ('BL'). For simple X-validation with the default
                   hyperparameterssetting, choose 'XV'
```


Outputs will be generated in the `../out/` folder. The program will output the following progress updates through the standard output:

```
PARSING TRAIN
PARSING TEST
...
LOSS_TEST X DEGREE N
LOSS_TEST X DEGREE N
LOSS_TEST X DEGREE N
...
MIN TEST ERROR: Y FOR M DEGREE
```

### Check

To run the main program, the `check.py` has to be executed from the scripts folder:

```
cd scripts/
python3 check.py
```

There are no command line arguments. It will look for a `train.csv` file located on `../data/` for training data. No file outputs will be generated.

The program will output the following progress updates through the standard output:

```
PARSING TRAIN
PARSING TEST
FILTERING DATA
BUILDING POLYNOMIALS
LEARNING MODEL BY LEAST SQUARES
X
LEARNING MODEL BY GRADIENT DESCENT
X
LEARNING MODEL BY STOCHASTIC GRADIENT DESCENT
X
LEAST SQUARES
W : [...]
MSE: X
GRADIENT DESCENT
W : [...]
MSE: X
STOCHASTIC GRADIENT DESCENT
W : [...]
MSE: X

```

### Data caching

Loading big datasets from `.csv` files is a slow task (roughly 15-20 seconds in a modern laptop), especially when developing. To solve this problem, a caching mechanism has been implemented: instead of loading raw `.csv`, the program loads `pickle`-encoded Python objects.

To do so, the main program detects if the required `.pckl` files are available in the `tmp/` folder. If so, it imports the objects into the variables used by the rest of the script. Otherwise it imports them from the `.csv` files and then dumps those objects to the `.pckl` files.
